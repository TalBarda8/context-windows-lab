{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Windows Lab - Complete Analysis\n",
    "\n",
    "This notebook provides comprehensive analysis of all four experiments:\n",
    "1. Needle in Haystack (Lost in the Middle)\n",
    "2. Context Window Size Impact\n",
    "3. RAG Impact\n",
    "4. Context Engineering Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(str(Path.cwd().parent / 'src'))\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('Set2')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Experiment 1: Needle in Haystack\n",
    "\n",
    "Analyzing the \"Lost in the Middle\" phenomenon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Experiment 1 results\n",
    "exp1_path = Path.cwd().parent / 'results' / 'exp1' / 'results.json'\n",
    "\n",
    "with open(exp1_path, 'r', encoding='utf-8') as f:\n",
    "    exp1_results = json.load(f)\n",
    "\n",
    "# Extract summary data\n",
    "exp1_summary = exp1_results['results_by_position']\n",
    "\n",
    "# Create DataFrame\n",
    "exp1_df = pd.DataFrame([\n",
    "    {'Position': pos.capitalize(), \n",
    "     'Mean Accuracy': data['mean_accuracy'],\n",
    "     'Success Rate': data['success_rate'],\n",
    "     'Correct': data['correct_count'],\n",
    "     'Total': data['total_count']}\n",
    "    for pos, data in exp1_summary.items()\n",
    "])\n",
    "\n",
    "print(\"Experiment 1 Summary:\")\n",
    "print(exp1_df.to_string(index=False))\n",
    "\n",
    "# Statistical test\n",
    "print(\"\\nKey Finding:\")\n",
    "middle_acc = exp1_summary['middle']['mean_accuracy']\n",
    "start_acc = exp1_summary['start']['mean_accuracy']\n",
    "end_acc = exp1_summary['end']['mean_accuracy']\n",
    "\n",
    "print(f\"Middle position accuracy ({middle_acc:.3f}) is significantly lower than\")\n",
    "print(f\"Start ({start_acc:.3f}) and End ({end_acc:.3f}) positions.\")\n",
    "print(f\"This demonstrates the 'Lost in the Middle' phenomenon.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Experiment 2: Context Window Size Impact\n",
    "\n",
    "Analyzing how context size affects performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Experiment 2 results\n",
    "exp2_path = Path.cwd().parent / 'results' / 'exp2' / 'results.json'\n",
    "\n",
    "with open(exp2_path, 'r', encoding='utf-8') as f:\n",
    "    exp2_results = json.load(f)\n",
    "\n",
    "# Create DataFrame\n",
    "exp2_df = pd.DataFrame(exp2_results['results_summary'])\n",
    "\n",
    "print(\"Experiment 2 Summary:\")\n",
    "print(exp2_df.to_string(index=False))\n",
    "\n",
    "# Calculate degradation\n",
    "initial_acc = exp2_df.iloc[0]['accuracy_mean']\n",
    "final_acc = exp2_df.iloc[-1]['accuracy_mean']\n",
    "degradation = ((initial_acc - final_acc) / initial_acc) * 100\n",
    "\n",
    "print(f\"\\nAccuracy degradation: {degradation:.1f}% ({initial_acc:.3f} → {final_acc:.3f})\")\n",
    "\n",
    "# Latency increase\n",
    "initial_lat = exp2_df.iloc[0]['latency_mean']\n",
    "final_lat = exp2_df.iloc[-1]['latency_mean']\n",
    "lat_increase = ((final_lat - initial_lat) / initial_lat) * 100\n",
    "\n",
    "print(f\"Latency increase: {lat_increase:.1f}% ({initial_lat:.2f}s → {final_lat:.2f}s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experiment 3: RAG Impact\n",
    "\n",
    "Comparing RAG with full-context approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Experiment 3 results\n",
    "exp3_path = Path.cwd().parent / 'results' / 'exp3' / 'results.json'\n",
    "\n",
    "with open(exp3_path, 'r', encoding='utf-8') as f:\n",
    "    exp3_results = json.load(f)\n",
    "\n",
    "# Extract comparison data\n",
    "comparison = exp3_results['comparison']\n",
    "\n",
    "# Create DataFrame\n",
    "exp3_df = pd.DataFrame([\n",
    "    {'Method': 'Full Context', **comparison['full_context']},\n",
    "    {'Method': 'RAG', **comparison['rag']}\n",
    "])\n",
    "\n",
    "print(\"Experiment 3 Summary:\")\n",
    "print(exp3_df.to_string(index=False))\n",
    "\n",
    "# Calculate improvements\n",
    "acc_improvement = ((comparison['rag']['accuracy'] - comparison['full_context']['accuracy']) / \n",
    "                   comparison['full_context']['accuracy']) * 100\n",
    "speedup = comparison['full_context']['latency'] / comparison['rag']['latency']\n",
    "token_reduction = ((comparison['full_context']['tokens_used'] - comparison['rag']['tokens_used']) / \n",
    "                   comparison['full_context']['tokens_used']) * 100\n",
    "\n",
    "print(f\"\\nRAG Improvements:\")\n",
    "print(f\"  Accuracy: {acc_improvement:+.1f}%\")\n",
    "print(f\"  Speedup: {speedup:.2f}x faster\")\n",
    "print(f\"  Token reduction: {token_reduction:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experiment 4: Context Engineering Strategies\n",
    "\n",
    "Comparing SELECT, COMPRESS, and WRITE strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Experiment 4 results\n",
    "exp4_path = Path.cwd().parent / 'results' / 'exp4' / 'results.json'\n",
    "\n",
    "with open(exp4_path, 'r', encoding='utf-8') as f:\n",
    "    exp4_results = json.load(f)\n",
    "\n",
    "# Extract summary\n",
    "exp4_summary = exp4_results['summary']\n",
    "\n",
    "# Create DataFrame\n",
    "exp4_df = pd.DataFrame([\n",
    "    {'Strategy': strategy.upper(), \n",
    "     'Mean Accuracy': data['mean_accuracy'],\n",
    "     'Correct': data['correct_count'],\n",
    "     'Total': data['total_steps']}\n",
    "    for strategy, data in exp4_summary.items()\n",
    "])\n",
    "\n",
    "print(\"Experiment 4 Summary:\")\n",
    "print(exp4_df.to_string(index=False))\n",
    "\n",
    "# Find best strategy\n",
    "best_strategy = exp4_df.loc[exp4_df['Mean Accuracy'].idxmax()]['Strategy']\n",
    "best_acc = exp4_df['Mean Accuracy'].max()\n",
    "\n",
    "print(f\"\\nBest Strategy: {best_strategy} with {best_acc:.3f} mean accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Combined Analysis and Conclusions\n",
    "\n",
    "Overall findings from all experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"OVERALL CONCLUSIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. Lost in the Middle Phenomenon (Exp 1):\")\n",
    "print(f\"   - Information in the middle of context windows is {degradation:.1f}% less\")\n",
    "print(f\"     accurately retrieved compared to start/end positions.\")\n",
    "\n",
    "print(\"\\n2. Context Size Impact (Exp 2):\")\n",
    "print(f\"   - Increasing context size from 2 to 50 documents leads to:\")\n",
    "print(f\"     • {degradation:.1f}% accuracy degradation\")\n",
    "print(f\"     • {lat_increase:.1f}% latency increase\")\n",
    "\n",
    "print(\"\\n3. RAG Effectiveness (Exp 3):\")\n",
    "print(f\"   - RAG provides:\")\n",
    "print(f\"     • {acc_improvement:+.1f}% accuracy improvement\")\n",
    "print(f\"     • {speedup:.2f}x faster response time\")\n",
    "print(f\"     • {token_reduction:.1f}% reduction in tokens used\")\n",
    "\n",
    "print(\"\\n4. Context Management Strategies (Exp 4):\")\n",
    "print(f\"   - {best_strategy} strategy performs best for multi-step tasks\")\n",
    "print(f\"   - All strategies help maintain accuracy over time\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEY TAKEAWAY:\")\n",
    "print(\"RAG-based approaches (SELECT strategy) offer the best combination\")\n",
    "print(\"of accuracy, speed, and efficiency for managing large context windows.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizations\n",
    "\n",
    "Load and display generated plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Display all plots\n",
    "plots = [\n",
    "    ('Experiment 1: Accuracy by Position', '../results/exp1/accuracy_by_position.png'),\n",
    "    ('Experiment 2: Context Size Impact', '../results/exp2/context_size_impact.png'),\n",
    "    ('Experiment 3: RAG Comparison', '../results/exp3/rag_comparison.png'),\n",
    "    ('Experiment 4: Strategy Comparison', '../results/exp4/strategy_comparison.png'),\n",
    "]\n",
    "\n",
    "for title, path in plots:\n",
    "    plot_path = Path.cwd().parent / path.replace('../', '')\n",
    "    if plot_path.exists():\n",
    "        print(f\"\\n{title}\")\n",
    "        display(Image(filename=str(plot_path)))\n",
    "    else:\n",
    "        print(f\"\\n{title}: Plot not found at {plot_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
