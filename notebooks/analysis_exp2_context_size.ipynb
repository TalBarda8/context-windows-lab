{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: Context Window Size Impact Analysis\n",
    "\n",
    "Analyzing how increasing context window size affects performance, latency, and token usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(str(Path.cwd().parent / 'src'))\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('Set2')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Analyze Results\n",
    "\n",
    "Load experimental results across different context sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Experiment 2 results\n",
    "exp2_path = Path.cwd().parent / 'results' / 'exp2' / 'results.json'\n",
    "\n",
    "with open(exp2_path, 'r', encoding='utf-8') as f:\n",
    "    exp2_results = json.load(f)\n",
    "\n",
    "# Create DataFrame\n",
    "exp2_df = pd.DataFrame(exp2_results['results_summary'])\n",
    "\n",
    "print(\"Experiment 2 Summary:\")\n",
    "print(exp2_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Degradation Analysis\n",
    "\n",
    "Quantify how performance degrades with context size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate degradation\n",
    "initial_acc = exp2_df.iloc[0]['accuracy_mean']\n",
    "final_acc = exp2_df.iloc[-1]['accuracy_mean']\n",
    "degradation = ((initial_acc - final_acc) / initial_acc) * 100\n",
    "\n",
    "print(f\"\\nAccuracy degradation: {degradation:.1f}% ({initial_acc:.3f} → {final_acc:.3f})\")\n",
    "\n",
    "# Latency increase\n",
    "initial_lat = exp2_df.iloc[0]['latency_mean']\n",
    "final_lat = exp2_df.iloc[-1]['latency_mean']\n",
    "lat_increase = ((final_lat - initial_lat) / initial_lat) * 100\n",
    "\n",
    "print(f\"Latency increase: {lat_increase:.1f}% ({initial_lat:.2f}s → {final_lat:.2f}s)\")\n",
    "\n",
    "# Token usage increase\n",
    "initial_tokens = exp2_df.iloc[0]['tokens_mean']\n",
    "final_tokens = exp2_df.iloc[-1]['tokens_mean']\n",
    "token_increase = ((final_tokens - initial_tokens) / initial_tokens) * 100\n",
    "\n",
    "print(f\"Token usage increase: {token_increase:.1f}% ({initial_tokens:.0f} → {final_tokens:.0f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Display the multi-panel impact analysis plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Display plot\n",
    "plot_path = Path.cwd().parent / 'results' / 'exp2' / 'context_size_impact.png'\n",
    "if plot_path.exists():\n",
    "    print(\"Context Size Impact (Accuracy, Latency, Tokens):\")\n",
    "    display(Image(filename=str(plot_path)))\n",
    "else:\n",
    "    print(f\"Plot not found at {plot_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "**Key Findings:**\n",
    "1. Accuracy degrades as context size increases (diminishing returns)\n",
    "2. Latency increases significantly with larger contexts\n",
    "3. Token usage grows proportionally with document count\n",
    "\n",
    "**Trade-offs:**\n",
    "- **Small contexts (2-5 docs)**: High accuracy, low latency, efficient\n",
    "- **Medium contexts (10-20 docs)**: Moderate accuracy, acceptable latency\n",
    "- **Large contexts (50+ docs)**: Degraded accuracy, high latency, expensive\n",
    "\n",
    "**Recommendations:**\n",
    "- Use RAG to limit context size to most relevant chunks\n",
    "- Optimal context size depends on accuracy requirements and budget\n",
    "- Monitor token limits to avoid truncation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
