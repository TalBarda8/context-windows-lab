# Context Windows Lab - Environment Configuration Template
# Copy this file to .env and customize values for your environment
# Usage: cp .env.example .env

# ==============================================================================
# OLLAMA CONFIGURATION
# ==============================================================================

# Ollama server base URL
# Default: http://localhost:11434
# For remote server: http://<ip-address>:11434
OLLAMA_BASE_URL=http://localhost:11434

# Primary LLM model to use
# Options: llama2, llama3.2, mistral, phi, gemma, etc.
# Run 'ollama list' to see available models
PRIMARY_MODEL=llama2

# Fallback model if primary is unavailable
FALLBACK_MODEL=mistral

# LLM temperature (0.0 = deterministic, 2.0 = creative)
# For reproducibility, use 0.0
LLM_TEMPERATURE=0.0

# LLM top_p parameter (nucleus sampling)
LLM_TOP_P=1.0

# ==============================================================================
# EMBEDDING MODEL CONFIGURATION
# ==============================================================================

# Sentence-transformers model for embeddings
# Options:
#   - all-MiniLM-L6-v2 (fast, 384 dims, recommended)
#   - all-mpnet-base-v2 (slower, 768 dims, higher quality)
#   - paraphrase-multilingual-MiniLM-L12-v2 (multilingual)
EMBEDDING_MODEL=all-MiniLM-L6-v2

# ==============================================================================
# EXPERIMENT CONFIGURATION
# ==============================================================================

# Random seed for reproducibility
# Use same seed across runs for deterministic results
RANDOM_SEED=42

# Context window size limits (in tokens)
DEFAULT_CONTEXT_WINDOW=4096
MAX_CONTEXT_WINDOW=4096

# ==============================================================================
# EXPERIMENT 1: NEEDLE IN HAYSTACK
# ==============================================================================

# Number of documents to generate per test
EXP1_NUM_DOCUMENTS=5

# Words per document
EXP1_WORDS_PER_DOCUMENT=200

# Number of iterations per position
EXP1_ITERATIONS_PER_POSITION=10

# ==============================================================================
# EXPERIMENT 2: CONTEXT WINDOW SIZE IMPACT
# ==============================================================================

# Document counts to test (comma-separated)
# Example: 2,5,10,20,50
EXP2_DOCUMENT_COUNTS=2,5,10,20,50

# Words per document
EXP2_WORDS_PER_DOCUMENT=200

# Number of iterations per context size
EXP2_ITERATIONS_PER_SIZE=5

# ==============================================================================
# EXPERIMENT 3: RAG IMPACT
# ==============================================================================

# Number of Hebrew documents in corpus
EXP3_NUM_DOCUMENTS=20

# RAG chunk size (in tokens)
EXP3_CHUNK_SIZE=500

# Overlap between chunks (in tokens)
EXP3_CHUNK_OVERLAP=50

# Number of chunks to retrieve (top-k)
EXP3_TOP_K_RETRIEVAL=3

# ==============================================================================
# EXPERIMENT 4: CONTEXT ENGINEERING STRATEGIES
# ==============================================================================

# Number of sequential agent actions
EXP4_NUM_ACTIONS=10

# Token threshold for compression trigger
EXP4_MAX_TOKENS_THRESHOLD=2048

# Top-k for SELECT strategy
EXP4_SELECT_TOP_K=5

# Scratchpad capacity for WRITE strategy
EXP4_SCRATCHPAD_CAPACITY=20

# ==============================================================================
# EVALUATION SETTINGS
# ==============================================================================

# Similarity threshold for semantic matching
SIMILARITY_THRESHOLD=0.8

# Enable/disable evaluation methods (true/false)
USE_EXACT_MATCH=true
USE_KEYWORD_MATCH=true
USE_SEMANTIC_MATCH=true

# ==============================================================================
# VISUALIZATION SETTINGS
# ==============================================================================

# Figure size (width,height in inches)
PLOT_FIGSIZE=10,6

# DPI for saved images (higher = better quality, larger file)
PLOT_DPI=300

# Matplotlib style
PLOT_STYLE=seaborn-v0_8-darkgrid

# Color palette (seaborn palettes: Set1, Set2, Set3, Paired, etc.)
PLOT_COLOR_PALETTE=Set2

# Image save format (png, pdf, svg)
PLOT_SAVE_FORMAT=png

# ==============================================================================
# LOGGING CONFIGURATION
# ==============================================================================

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Log format
LOG_FORMAT="%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# Log date format
LOG_DATE_FORMAT="%Y-%m-%d %H:%M:%S"

# Log to file (true/false)
LOG_TO_FILE=false

# Log file path (if LOG_TO_FILE=true)
LOG_FILE_PATH=logs/experiment.log

# ==============================================================================
# PATHS (Advanced - usually don't need to change)
# ==============================================================================

# Override default data directory (relative to project root)
# DATA_DIR=data

# Override default results directory
# RESULTS_DIR=results

# Override default notebooks directory
# NOTEBOOKS_DIR=notebooks

# ==============================================================================
# PERFORMANCE TUNING
# ==============================================================================

# Ollama request timeout (seconds)
OLLAMA_TIMEOUT=30

# Number of retry attempts for failed LLM calls
LLM_RETRY_ATTEMPTS=3

# Retry backoff factor (exponential backoff)
LLM_RETRY_BACKOFF=2

# Maximum concurrent LLM requests (for future parallel processing)
MAX_CONCURRENT_REQUESTS=1

# ==============================================================================
# DEVELOPMENT / DEBUG OPTIONS
# ==============================================================================

# Enable verbose output (true/false)
VERBOSE=false

# Enable debug mode (includes extra logging and validation)
DEBUG=false

# Disable progress bars (useful for logging to files)
DISABLE_PROGRESS_BARS=false

# Save intermediate results (useful for debugging)
SAVE_INTERMEDIATE_RESULTS=false

# ==============================================================================
# SECURITY & PRIVACY
# ==============================================================================

# Disable telemetry/analytics (if applicable)
DISABLE_TELEMETRY=true

# Sanitize logs (remove sensitive data)
SANITIZE_LOGS=true

# ==============================================================================
# NOTES
# ==============================================================================

# 1. Lines starting with # are comments
# 2. Values with spaces should NOT be quoted
# 3. Boolean values: true, false (lowercase)
# 4. Numeric values: no quotes
# 5. String values: no quotes needed
# 6. Comma-separated lists: no spaces after commas

# ==============================================================================
# QUICK START
# ==============================================================================

# For first-time setup:
# 1. Copy this file: cp .env.example .env
# 2. Install Ollama from https://ollama.ai
# 3. Pull a model: ollama pull llama2
# 4. Verify setup: ollama list
# 5. Run experiments: python -m src.experiments.exp1_needle_haystack

# For custom configurations:
# - Edit .env file (never commit .env to git!)
# - Restart your Python session to load new values
# - Override with environment variables: RANDOM_SEED=100 python -m src.experiments.exp1_needle_haystack
